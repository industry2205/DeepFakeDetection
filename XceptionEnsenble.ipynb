{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom PIL import Image\nimport cv2, sys, re\nimport pandas as pd\nimport numpy as np\nimport random\nfrom keras import models,Sequential,layers\nfrom keras.models import Model, Input\nfrom keras.layers import Conv2D, SeparableConv2D, Dense, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\nfrom keras.layers import Activation, BatchNormalization, Dropout, Flatten, Reshape\nfrom keras.layers import Add\nfrom keras.utils import to_categorical\nfrom keras.callbacks import Callback\nfrom keras.optimizers import SGD,Adam\nfrom keras.regularizers import l2\nfrom keras.datasets import cifar10\nimport numpy as np\nimport keras.backend as K\nfrom sklearn.metrics import log_loss\nimport glob\nfrom keras.models import load_model\nimport tensorflow as tf\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport tensorflow as tf\n\nfrom keras import backend as K\nfrom keras.models import Model\n\nfrom keras.layers import Conv2D, BatchNormalization, ReLU, DepthwiseConv2D, Activation, Input, Add\nfrom keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Softmax, Flatten\n\n# ** to update custom Activate functions\nfrom keras.utils.generic_utils import get_custom_objects","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_train_dirs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_train_dirs = glob.glob('/kaggle/input/all-data/dfdc_train_part/' + 'dfdc_train_part_*')\n# for i, train_dir in enumerate(all_train_dirs):\n#     print('[{:02}]'.format(i), train_dir)\nall_train_dirs.sort()\ndel all_train_dirs[12]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_train_dirs = glob.glob('/kaggle/input/deepfake-detection-faces-part-*/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_train_dirs[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(all_train_dirs[12])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(path,file_list,label_img):\n    a = [0,50,100,150,200,250,300]\n    im = []\n    label = []\n    for i in file_list:\n        path_dir = path +'/' + i\n        for j in a:\n            try:\n                img = Image.open(path_dir + '/' + str(j) +'.png')\n                arr_img = list(np.array(img))\n                im.append(arr_img)\n\n                label_list = np.array(label_img.iloc[:, [3]])\n\n                if i + '.mp4' in label_list:\n                    label.append(1)  # Deepfake\n                else:\n                    label.append(0)\n            except:\n                pass\n    return im, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eye_cascade = cv2.CascadeClassifier('/kaggle/input/haar-cascades-for-face-detection/haarcascade_eye.xml')\n\ndef detection_eyes(a):\n    roi_gray = a[0:160,0:160]\n    eyes = eye_cascade.detectMultiScale(roi_gray)\n    cnt_eyes = 0\n    for (ex,ey,ew,eh) in eyes:\n        cnt_eyes += 1\n    return cnt_eyes\n\ndef read_image(path,file_list,label_img):\n    a = [150,250]\n    im = []\n    label = []\n    for i in file_list:\n        path_dir = path +'/' + i\n        for j in a:\n            try:\n                img = Image.open(path_dir + '/' + str(j) +'.png')\n                arr_img = np.array(img)\n                if detection_eyes(arr_img) == 1:\n#                 if detection_eyes(arr_img) != 1:\n                    im.append(list(arr_img))\n                    label_list = np.array(label_img.iloc[:, [2]])\n                    if i + '.mp4' in label_list:\n                        label.append(1)  # Deepfake\n                    else:\n                        label.append(0)\n            except:\n                pass\n    return im, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 전체 데이터셋 real:deep = 21184:1199\n# 폴더 11개 데이터셋 real:deep = 6851:504 (결과 잘 나왔었음)\n\nX = []\ny = []\n# len(all_train_dirs) range 안에 대입\nfor i in range(1):\n    path = all_train_dirs[i]\n    file_list = os.listdir(path)\n    label = pd.read_csv(all_train_dirs[i] + '/metadata.csv',delimiter=',')\n    img,label = read_image(path,file_list,label)\n    X += img\n    y += label\n\nX = np.array(X)\ny = np.array(y).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\neye_cascade = cv2.CascadeClassifier('/kaggle/input/haar-cascades-for-face-detection/haarcascade_eye.xml')\ndef detection_eyes(a):\n#     img = cv2.rectangle(a,(0,0),(160,160),(255,0,0),2)\n#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    roi_gray = a[0:160,0:160]\n#     roi_color = img[0:160,0:160]\n    eyes = eye_cascade.detectMultiScale(roi_gray)\n    cnt_eyes = 0\n    for (ex,ey,ew,eh) in eyes:\n        cnt_eyes += 1\n#         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n    return cnt_eyes\n\nA = []\nA_side = []\ny = np.array([])\ny_side = np.array([])\n\nfor k,a in enumerate(X):\n    if detection_eyes(a) == 1:\n        A.append(X[k])\n        y = np.append(y,B[k])\n    else:\n        A_side.append(X[k])\n        y_side = np.append(y,B[k])\nA = np.squeeze(np.array(X))\nA_side = np.squeeze(np.array(X_side))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터셋 0,1로 분류해서 인덱싱 하기 위함\nc = []\nd = []\ne = []\nf = []\n\n\nfor i in range(len(y)):\n    if y[i] == 0:\n        c.append(y[i])\n        d.append(X[i])\n\nfor i in range(len(y)):\n    if y[i] == 1:\n        e.append(y[i])\n        f.append(X[i])\n\nX = np.array(f+d)\ny = np.array(e+c).reshape(-1,1)\nprint(len(X))\nprint(len(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=0\nfor i in range(len(y)):\n    if y[i] == 0:\n        a += 1\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del c\ndel d\ndel e\ndel f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A = X[2000:14000]\nB = y[2000:14000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X\ndel y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\nfrom keras import backend as K\nfrom keras.activations import sigmoid\n\n\ndef cbam_block(cbam_feature, ratio=8):\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature)\n\treturn cbam_feature\n\ndef channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature._keras_shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t activation='relu',\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('sigmoid')(cbam_feature)\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])\n\ndef spatial_attention(input_feature):\n\tkernel_size = 1024\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature._keras_shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature._keras_shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool._keras_shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool._keras_shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat._keras_shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tactivation='sigmoid',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\t\n\tassert cbam_feature._keras_shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def divide(x, y, train_prop):\n    random.seed(1234)\n    tmp = np.random.permutation(np.arange(len(x)))\n    X_train = x[tmp][:-(len(x)-round(train_prop * len(x)))]\n    y_train = y[tmp][:-(len(x)-round(train_prop * len(x)))]\n    X_test = x[tmp][-(len(x)-round(train_prop * len(x))):]\n    y_test = y[tmp][-(len(x)-round(train_prop * len(x))):]\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = divide(X,y,0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del A\ndel B","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def divide(x, y):\n    random.seed(1234)\n    tmp = np.random.permutation(np.arange(len(x)))\n    X_train = x[tmp][:]\n    y_train = y[tmp][:]\n    return X_train, y_train\n\nX_train, y_train = divide(A,B)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=1e-5):\n    x = Conv2D(filters, kernel_size, padding=padding, strides=strides, kernel_regularizer=l2(weight_decay))(x)\n    x = BatchNormalization()(x)\n    if activation:\n        x = Activation(activation)(x)\n\n    return x\n\ndef sepconv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=1e-5,\n                 depth_multiplier=1):\n    x = SeparableConv2D(filters, kernel_size, padding=padding, strides=strides, depth_multiplier=depth_multiplier,\n                        depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay))(x)\n    x = BatchNormalization()(x)\n\n    if activation:\n        x = Activation(activation)(x)\n\n    return x\n\n\ndef Xception(model_input, classes):\n    ## Entry flow\n    x = conv2d_bn(model_input, 32, (3, 3), strides=2)  # (299, 299, 3) -> (150, 150, 32)\n    x = conv2d_bn(x, 64, (3, 3))\n\n    for fliters in [128, 256, 728]:  # (75, 75, 64) -> (75, 75, 128) -> (38, 38, 256) -> (19, 19, 728)\n        residual = conv2d_bn(x, fliters, (1, 1), strides=2, activation=None)\n\n        x = Activation(activation='relu')(x)\n        x = sepconv2d_bn(x, fliters, (3, 3))\n        x = sepconv2d_bn(x, fliters, (3, 3), activation=None)\n        x = MaxPooling2D((3, 3), padding='same', strides=2)(x)\n        # 1X1 convolution layer를 activation 대신에 마지막에 적용시킨다.\n        x = Add()([x, residual])\n\n    ## Middle flow\n    for i in range(8):  # (19, 19, 728)\n        residual = x\n\n        x = sepconv2d_bn(x, 728, (3, 3))\n        x = sepconv2d_bn(x, 728, (3, 3))\n        x = sepconv2d_bn(x, 728, (3, 3), activation=None)\n\n        x = Add()([x, residual])\n\n    ## Exit flow\n    residual = conv2d_bn(x, 1024, (1, 1), strides=2, activation=None)  # (19, 19, 728) -> (10, 10, 1024)\n\n    x = Activation(activation='relu')(x)\n    x = sepconv2d_bn(x, 728, (3, 3))\n    x = sepconv2d_bn(x, 1024, (3, 3), activation=None)  # (19, 19, 728) -> (19, 19, 1024)\n    x = MaxPooling2D((3, 3), padding='same', strides=2)(x)  # (19, 19, 1024) -> (10, 10, 1024)\n\n    x = Add()([x, residual])\n\n    x = sepconv2d_bn(x, 1536, (3, 3))\n    x = sepconv2d_bn(x, 2048, (3, 3))\n    x = cbam_block(x)\n    \n    x = GlobalAveragePooling2D()(x)\n\n    ## Optinal fully-connected layers\n    \n#     x = Dense(4096)(x)\n#     x = BatchNormalization()(x)\n#     x = Activation(activation='relu')(x)\n\n#     x = Dense(4096)(x)\n#     x = BatchNormalization()(x)\n#     x = Activation(activation='relu')(x)\n    \n    x = Dropout(0.5)(x)\n#     x = BatchNormalization()(x)\n\n    model_output = Dense(classes, activation='softmax')(x)\n    model = Model(model_input, model_output, name='Xception')\n    return model\n\nclass LearningRateSchedule(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch+1)%2 == 0:\n            lr = K.get_value(self.model.optimizer.lr)\n            K.set_value(self.model.optimizer.lr, lr*0.94)\n\ninput_shape = (160, 160, 3)\n\nX_train = X_train.astype('float32')/255.\n# X_test = X_test.astype('float32')/255.\n\ny_train = to_categorical(y_train, num_classes=2)\n# y_test = to_categorical(y_test, num_classes=2)\n\nmodel_input = Input(shape=input_shape)\n\nmodel = Xception(model_input,2)\n\noptimizer = SGD(lr=0.0009, momentum=0.9)\n# optimizer = Adam(lr=0.0017, beta_1=0.9, beta_2=0.999, epsilon=10e-8, decay=1e-7, amsgrad=False)\n\ncallbacks_list = [LearningRateSchedule()]\n\nmodel.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n\nmodel.fit(X_train, y_train, batch_size=64, epochs=15, validation_split=0.25, callbacks=callbacks_list)\n\n# y_pred = model.predict(X_test)\n             \n# a = log_loss(y_test,y_pred)\n# print(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mobile net\n\nimport tensorflow as tf\n\nfrom keras import backend as K\nfrom keras.models import Model\n\nfrom keras.layers import Conv2D, BatchNormalization, ReLU, DepthwiseConv2D, Activation, Input, Add\nfrom keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Softmax, Flatten\n\n# ** to update custom Activate functions\nfrom keras.utils.generic_utils import get_custom_objects\n\n\n\"\"\" Define layers block functions \"\"\"\ndef Hswish(x):\n    return x * tf.nn.relu6(x + 3) / 6\n\n# ** update custom Activate functions\nget_custom_objects().update({'custom_activation': Activation(Hswish)})\n\n\ndef __conv2d_block(_inputs, filters, kernel, strides, is_use_bias=False, padding='same', activation='RE', name=None):\n    x = Conv2D(filters, kernel, strides= strides, padding=padding, use_bias=is_use_bias)(_inputs)\n    x = BatchNormalization()(x)\n    if activation == 'RE':\n        x = ReLU(name=name)(x)\n    elif activation == 'HS':\n        x = Activation(Hswish, name=name)(x)\n    else:\n        raise NotImplementedError\n    return x\n\ndef __depthwise_block(_inputs, kernel=(3, 3), strides=(1, 1), activation='RE', is_use_se=True, num_layers=0):\n    x = DepthwiseConv2D(kernel_size=kernel, strides=strides, depth_multiplier=1, padding='same')(_inputs)\n    x = BatchNormalization()(x)\n    if is_use_se:\n        x = __se_block(x)\n    if activation == 'RE':\n        x = ReLU()(x)\n    elif activation == 'HS':\n        x = Activation(Hswish)(x)\n    else:\n        raise NotImplementedError\n    return x\n\ndef __global_depthwise_block(_inputs):\n    assert _inputs._keras_shape[1] == _inputs._keras_shape[2]\n    kernel_size = _inputs._keras_shape[1]\n    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(1, 1), depth_multiplier=1, padding='valid')(_inputs)\n    return x\n\ndef __se_block(_inputs, ratio=4, pooling_type='avg'):\n    filters = _inputs._keras_shape[-1]\n    se_shape = (1, 1, filters)\n    if pooling_type == 'avg':\n        se = GlobalAveragePooling2D()(_inputs)\n    elif pooling_type == 'depthwise':\n        se = __global_depthwise_block(_inputs)\n    else:\n        raise NotImplementedError\n    se = Reshape(se_shape)(se)\n    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n    se = Dense(filters, activation='hard_sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n    return multiply([_inputs, se])\n\ndef __bottleneck_block(_inputs, out_dim, kernel, strides, expansion_dim, is_use_bias=False, shortcut=True, is_use_se=True, activation='RE', num_layers=0, *args):\n    with tf.name_scope('bottleneck_block'):\n        # ** to high dim \n        bottleneck_dim = expansion_dim\n\n        # ** pointwise conv \n        x = __conv2d_block(_inputs, bottleneck_dim, kernel=(1, 1), strides=(1, 1), is_use_bias=is_use_bias, activation=activation)\n\n        # ** depthwise conv\n        x = __depthwise_block(x, kernel=kernel, strides=strides, is_use_se=is_use_se, activation=activation, num_layers=num_layers)\n\n        # ** pointwise conv\n        x = Conv2D(out_dim, (1, 1), strides=(1, 1), padding='same')(x)\n        x = BatchNormalization()(x)\n\n        if shortcut and strides == (1, 1):\n            in_dim = K.int_shape(_inputs)[-1]\n            if in_dim != out_dim:\n                ins = Conv2D(out_dim, (1, 1), strides=(1, 1), padding='same')(_inputs)\n                x = Add()([x, ins])\n            else:\n                x = Add()([x, _inputs])\n    return x\n\ndef build_mobilenet_v3(input_size, num_classes, model_type='large', pooling_type='avg', include_top=True):\n    # ** input layer\n    inputs = Input(shape=(input_size, input_size, 3))\n\n    # ** feature extraction layers\n    net = __conv2d_block(inputs, 16, kernel=(3, 3), strides=(2, 2), is_use_bias=False, padding='same', activation='HS') \n    if model_type == 'large':\n        config_list = large_config_list\n    elif model_type == 'small':\n        config_list = small_config_list\n    else:\n        raise NotImplementedError\n        \n    for config in config_list:\n        net = __bottleneck_block(net, *config)\n    \n    # ** final layers\n    net = __conv2d_block(net, 960, kernel=(3, 3), strides=(1, 1), is_use_bias=True, padding='same', activation='HS', name='output_map')\n    net = cbam_block(net)\n    net = AveragePooling2D((3,3), padding='same', strides=2)(net)\n    print(net.shape)\n#     if pooling_type == 'avg':\n#         net = GlobalAveragePooling2D()(net)\n\n#     elif pooling_type == 'depthwise':\n#         net = __global_depthwise_block(net)\n#     else:\n#         raise NotImplementedError\n\n    net = BatchNormalization()(net)\n\n    a = Flatten()(net)\n    a = Dense(8640)(a)\n    a = BatchNormalization()(a)\n    a = Activation(activation='relu')(a)\n    \n#     a = Dense(8640)(a)\n#     a = BatchNormalization()(a)\n#     a = Activation(activation='relu')(a)\n\n#     a = Dropout(0.5)(a)\n    a = BatchNormalization()(a)\n\n    \n    model_output = Dense(num_classes, activation='softmax')(a)\n    model = Model(inputs=inputs, outputs=model_output)\n\n    return model\n\n\"\"\" define bottleneck structure \"\"\"\n# ** \n# **             \nglobal large_config_list    \nglobal small_config_list\n\nlarge_config_list = [[16,  (3, 3), (1, 1), 16,  False, False, False, 'RE',  0],\n                     [24,  (3, 3), (2, 2), 64,  False, False, False, 'RE',  1],\n                     [24,  (3, 3), (1, 1), 72,  False, True,  False, 'RE',  2],\n                     [40,  (5, 5), (2, 2), 72,  False, False, True,  'RE',  3],\n                     [40,  (5, 5), (1, 1), 120, False, True,  True,  'RE',  4],\n                     [40,  (5, 5), (1, 1), 120, False, True,  True,  'RE',  5],\n                     [80,  (3, 3), (2, 2), 240, False, False, False, 'RE',  6],\n                     [80,  (3, 3), (1, 1), 200, False, True,  False, 'RE',  7],\n                     [80,  (3, 3), (1, 1), 184, False, True,  False, 'RE',  8],\n                     [80,  (3, 3), (1, 1), 184, False, True,  False, 'RE',  9],\n                     [112, (3, 3), (1, 1), 480, False, False, True,  'RE', 10],\n                     [112, (3, 3), (1, 1), 672, False, True,  True,  'RE', 11],\n                     [160, (5, 5), (1, 1), 672, False, False, True,  'RE', 12],\n                     [160, (5, 5), (2, 2), 672, False, True,  True,  'RE', 13],\n                     [160, (5, 5), (1, 1), 960, False, True,  True,  'RE', 14]]\n\nsmall_config_list = [[16,  (3, 3), (2, 2), 16,  False, False, True,  'RE', 0],\n                     [24,  (3, 3), (2, 2), 72,  False, False, False, 'RE', 1],\n                     [24,  (3, 3), (1, 1), 88,  False, True,  False, 'RE', 2],\n                     [40,  (5, 5), (1, 1), 96,  False, False, True,  'RE', 3],\n                     [40,  (5, 5), (1, 1), 240, False, True,  True,  'RE', 4], \n                     [40,  (5, 5), (1, 1), 240, False, True,  True,  'RE', 5],\n                     [48,  (5, 5), (1, 1), 120, False, False, True,  'RE', 6],\n                     [48,  (5, 5), (1, 1), 144, False, True,  True,  'RE', 7],\n                     [96,  (5, 5), (2, 2), 288, False, False, True,  'RE', 8],\n                     [96,  (5, 5), (1, 1), 576, False, True,  True,  'RE', 9],\n                     [96,  (5, 5), (1, 1), 576, False, True,  True,  'RE', 10]]\n\n# large_config_list = [[16,  (3, 3), (1, 1), 16,  False, False, False, 'RE',  0],\n#                      [24,  (3, 3), (2, 2), 64,  False, False, False, 'RE',  1],\n#                      [24,  (3, 3), (1, 1), 72,  False, True,  False, 'RE',  2],\n#                      [40,  (5, 5), (2, 2), 72,  False, False, True,  'RE',  3],\n#                      [40,  (5, 5), (1, 1), 120, False, True,  True,  'RE',  4],\n#                      [40,  (5, 5), (1, 1), 120, False, True,  True,  'RE',  5],\n#                      [80,  (3, 3), (2, 2), 240, False, False, False, 'HS',  6],\n#                      [80,  (3, 3), (1, 1), 200, False, True,  False, 'HS',  7],\n#                      [80,  (3, 3), (1, 1), 184, False, True,  False, 'HS',  8],\n#                      [80,  (3, 3), (1, 1), 184, False, True,  False, 'HS',  9],\n#                      [112, (3, 3), (1, 1), 480, False, False, True,  'HS', 10],\n#                      [112, (3, 3), (1, 1), 672, False, True,  True,  'HS', 11],\n#                      [160, (5, 5), (1, 1), 672, False, False, True,  'HS', 12],\n#                      [160, (5, 5), (2, 2), 672, False, True,  True,  'HS', 13],\n#                      [160, (5, 5), (1, 1), 960, False, True,  True,  'HS', 14]]\n\n# small_config_list = [[16,  (3, 3), (2, 2), 16,  False, False, True,  'RE', 0],\n#                      [24,  (3, 3), (2, 2), 72,  False, False, False, 'RE', 1],\n#                      [24,  (3, 3), (1, 1), 88,  False, True,  False, 'RE', 2],\n#                      [40,  (5, 5), (1, 1), 96,  False, False, True,  'HS', 3],\n#                      [40,  (5, 5), (1, 1), 240, False, True,  True,  'HS', 4], \n#                      [40,  (5, 5), (1, 1), 240, False, True,  True,  'HS', 5],\n#                      [48,  (5, 5), (1, 1), 120, False, False, True,  'HS', 6],\n#                      [48,  (5, 5), (1, 1), 144, False, True,  True,  'HS', 7],\n#                      [96,  (5, 5), (2, 2), 288, False, False, True,  'HS', 8],\n#                      [96,  (5, 5), (1, 1), 576, False, True,  True,  'HS', 9],\n#                      [96,  (5, 5), (1, 1), 576, False, True,  True,  'HS', 10]]\n\n\n\"\"\" build MobileNet V3 model \"\"\"\n\ndef learning_rate_scheduler(epoch):\n    if epoch > 50:\n        lr = 1e-3\n    elif epoch > 100:\n        lr = 1e-4\n    elif epoch > 300:\n        lr = 5e-5\n    elif epoch > 500:\n        lr = 1e-5\n    elif epoch > 800:\n        lr = 1e-6\n    else:\n        lr = 3e-2\n    return lr\n\nclass LearningRateSchedule(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch+1)%2 == 0:\n            lr = K.get_value(self.model.optimizer.lr)\n            K.set_value(self.model.optimizer.lr, lr*0.94)\n\n\n# X_train = X_train.astype('float32')/255.\n# X_test = X_test.astype('float32')/255.\n\n# y_train = to_categorical(y_train, num_classes=2)\n# y_test = to_categorical(y_test, num_classes=2)\n\nmodel = build_mobilenet_v3(input_size=160, num_classes=2, model_type='large', pooling_type='avg', include_top=True)\n\noptimizer = SGD(lr=0.05, momentum=0.9)\n# optimizer = Adam(lr=1e-2, beta_1=0.9, beta_2=0.999, epsilon=10e-8, decay=1e-3, amsgrad=False)\n\ncallbacks_list = [LearningRateSchedule()]\n\nmodel.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n\nmodel.fit(X_train, y_train, batch_size=128, epochs=300, validation_split=0.25, callbacks=callbacks_list)\n\ny_pred = model.predict(X_test)\n             \na = log_loss(y_test,y_pred)\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = y_pred[:,1]\nb = y_test[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred[:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(y_pred[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test[5:10])\nprint(y_pred[5:10])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_loss(y_test[5:10],y_pred[5:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test[390:400])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred[:,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('mobilenet2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = pd.read_csv('/kaggle/input/deepfake-detection-faces-part-7-2/metadata.csv')\nfor i in range(600):\n    print(a.iloc[i,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature map 이미지 비교 위한 코딩\n\nfrom keras.models import load_model\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Layer가 많을수록 다양한 feature map을 얻는 것을 확인했다.\n\ndef show_image(img_path, target_size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n    img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n\n    # print(img_tensor[0, 0])                         # [31.  2.  6.]\n    # print(np.min(img_tensor), np.max(img_tensor))   # 0.0 255.0\n    # print(img_tensor.dtype, img_tensor.shape)       # float32 (150, 150, 3)\n\n    # 스케일링하지 않으면 이미지 출력 안됨\n    img_tensor /= 255\n\n    plt.imshow(img_tensor)\n    plt.show()\n\nshow_image('/kaggle/input/deepfake-detection-faces-part-3-1/qawbflilul/150.png', target_size=(150, 150))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keras의 load_model을 이용하면 에러가 발생\n\n# model = load_model('/kaggle/input/image-model/image_model_0.2955.h5')\nmodel = tf.keras.models.load_model('/kaggle/input/image-model/image_model_0.2955.h5')\n\n\n# model = tf.keras.models.load_model('/kaggle/input/mobilenet/mobilenet.h5')\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature map 시각화\n\n# 옆모습의 특징을 정면보다 잘 뽑아내지 못한다\n\n\n# 이미지 불러오기\ndef load_image(img_path, target_size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n    img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n\n    # 배치 사이즈 추가 + 스케일링 결과 반환\n    return img_tensor[np.newaxis] / 255     # (1, 150, 150, 3)\n\n\n# 첫 번째 등장하는 컨볼루션 레이어의 모든 피처맵(32개) 출력\ndef show_first_feature_map(loaded_model, img_path):\n    first_output = loaded_model.layers[2].output\n    print(first_output.shape, first_output.dtype)   # (?, 148, 148, 32) <dtype: 'float32'>\n\n    # 1개의 출력을 갖는 새로운 모델 생성\n    model = tf.keras.models.Model(inputs=loaded_model.input, outputs=first_output)\n\n    # 입력으로부터 높이와 너비를 사용해서 target_size에 해당하는 튜플 생성\n    target_size = (loaded_model.input.shape[2], loaded_model.input.shape[2])\n    img_tensor = load_image(img_path, target_size)\n\n    print(loaded_model.input.shape)     # (?, 150, 150, 3)\n    print(img_tensor.shape)             # (1, 150, 150, 3)\n\n    first_activation = model.predict(img_tensor)\n\n    # 컨볼루션 레이어에서 필터 크기(3), 스트라이드(1), 패딩(valid)을 사용했기 때문에\n    # 150에서 148로 크기가 일부 줄었음을 알 수 있다. 필터 개수는 32.\n    print(first_activation.shape)       # (1, 148, 148, 32)\n    print(first_activation[0, 0, 0])    # [0.00675746 0. 0.02397328 0.03818807 0. ...]\n\n    # 19번째 활성 맵 출력. 기본 cmap은 viridis. gray는 흑백 컬러맵.\n    # [0, :, :, feature_index]\n    # 0은 첫 번째 데이터(원본 이미지)의 피처맵을 가리킨다. 사진은 1장만 사용했기 때문에 0만 가능\n    # 가운데 콜론(:)은 높이와 너비를 가리키는 차원의 모든 데이터\n    # feature_index는 보고 싶은 피처맵이 있는 채널을 가리킨다.\n    # 32개의 필터를 사용했다면 0부터 31까지의 피처맵이 존재한다.\n    plt.figure(figsize=(16, 8))\n    for i in range(first_activation.shape[-1]):\n        plt.subplot(4, 8, i + 1)\n\n        # 눈금 제거. fignum은 같은 피켜에 연속 출력\n        plt.axis('off')\n        plt.matshow(first_activation[0, :, :, i], cmap='gray', fignum=0)\n    plt.tight_layout()\n    plt.show()\n\n# chhcmabekn = fake, \nshow_first_feature_map(model,'/kaggle/input/deepfake-detection-faces-part-3-0/vezsoxophr/150.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# model = tf.keras.Sequential()\n\n# model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(160, 160, 1), activation='relu'))\n# model.add(Conv2D(64, (3, 3), activation='relu'))\n# model.add(Conv2D(128, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=2))\n# model.add(MaxPooling2D(pool_size=2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(y_pred)):\n    if y_pred[i][0] > 0.09:\n        print(y_pred[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras import layers\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras_applications.imagenet_utils import _obtain_input_shape\n# from keras.utils.data_utils import get_file\n\n# WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5'\n\ndef Xception():\n\n\t# Determine proper input shape\n\tinput_shape = _obtain_input_shape(None, default_size=160, min_size=71, data_format='channels_last',require_flatten=False)\n\n\timg_input = Input(shape=input_shape)\n\n\t# Block 1\n\tx = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = Conv2D(64, (3, 3), use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\tresidual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 2\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 2 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 3\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 3 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 4\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 5 - 12\n\tfor i in range(8):\n\t\tresidual = x\n\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\n\t\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 13\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 13 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 14\n\tx = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Block 14 part 2\n\tx = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Fully Connected Layer\n\tx = GlobalAveragePooling2D()(x)\n\tx = Dense(1, activation='sigmoid')(x)\n\n\tinputs = img_input\n\n\t# Create model\n\tmodel = Model(inputs, x, name='xception')\n\n\t# Download and cache the Xception weights file\n# \tweights_path = get_file('xception_weights.h5', WEIGHTS_PATH, cache_subdir='models')\n\n\t# load weights\n# \tmodel.load_weights(weights_path)\n\n\treturn model\n\n\n\"\"\"\n\tInstantiate the model by using the following line of code\n\tmodel = Xception()\n\"\"\"\n\n\n# input_shape = (160, 160, 3)\n\nX_train = X_train.astype('float32')/255.\nX_test = X_test.astype('float32')/255.\n\n# y_train = to_categorical(y_train, num_classes=2)\n# y_test = to_categorical(y_test, num_classes=2)\n\n# model_input = Input(shape=input_shape)\n\nmodel = Xception()\n\n# optimizer = SGD(lr=0.0009, momentum=0.9)\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-8, decay=1e-5, amsgrad=False)\nclass LearningRateSchedule(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch+1)%2 == 0:\n            lr = K.get_value(self.model.optimizer.lr)\n            K.set_value(self.model.optimizer.lr, lr*0.94)\ncallbacks_list = [LearningRateSchedule()]\n\nmodel.compile(optimizer, loss='binary_crossentropy', metrics=['acc'])\n\nmodel.fit(X_train, y_train, batch_size=64, epochs=40, validation_split=0.25, callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=1e-5):\n    x = Conv2D(filters, kernel_size, padding=padding, strides=strides, kernel_regularizer=l2(weight_decay))(x)\n    x = BatchNormalization()(x)\n    if activation:\n        x = Activation(activation)(x)\n    return x\n\ndef sepconv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=1e-5,\n                 depth_multiplier=1):\n    x = SeparableConv2D(filters, kernel_size, padding=padding, strides=strides, depth_multiplier=depth_multiplier,\n                        depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay))(x)\n    x = BatchNormalization()(x)\n\n    if activation:\n        x = Activation(activation)(x)\n    return x\n\n\ndef Xception(model_input, classes):\n    ## Entry flow\n    x = conv2d_bn(model_input, 8, (3, 3), strides=2)  # (299, 299, 3) -> (150, 150, 32)\n    x = conv2d_bn(x, 16, (3, 3))\n\n    for fliters in [32, 64, 128]:  # (75, 75, 64) -> (75, 75, 128) -> (38, 38, 256) -> (19, 19, 728)\n        residual = conv2d_bn(x, fliters, (1, 1), strides=2, activation=None)\n\n        x = Activation(activation='relu')(x)\n        x = sepconv2d_bn(x, fliters, (3, 3))\n        x = sepconv2d_bn(x, fliters, (3, 3), activation=None)\n        x = MaxPooling2D((3, 3), padding='same', strides=2)(x)\n        # 1X1 convolution layer를 activation 대신에 마지막에 적용시킨다.\n        x = Add()([x, residual])\n\n    ## Middle flow\n    for i in range(8):  # (19, 19, 728)\n        residual = x\n\n        x = sepconv2d_bn(x, 128, (3, 3))\n        x = sepconv2d_bn(x, 128, (3, 3))\n        x = sepconv2d_bn(x, 128, (3, 3), activation=None)\n\n        x = Add()([x, residual])\n\n    ## Exit flow\n    residual = conv2d_bn(x, 256, (1, 1), strides=2, activation=None)  # (19, 19, 728) -> (10, 10, 1024)\n\n    x = Activation(activation='relu')(x)\n    x = sepconv2d_bn(x, 192, (3, 3))\n    x = sepconv2d_bn(x, 256, (3, 3), activation=None)  # (19, 19, 728) -> (19, 19, 1024)\n    x = MaxPooling2D((3, 3), padding='same', strides=2)(x)  # (19, 19, 1024) -> (10, 10, 1024)\n\n    x = Add()([x, residual])\n\n    x = sepconv2d_bn(x, 384, (3, 3))\n    x = sepconv2d_bn(x, 512, (3, 3))\n    x = cbam_block(x)\n    a = Flatten()(x)\n    a = Dense(12800)(a)\n    a = BatchNormalization()(a)\n    a = Activation(activation='relu')(a) # (1,12800)\n    a = Dropout(0.5)(a)\n    \n    model_output = Dense(classes, activation='softmax')(a)\n    model = Model(model_input, model_output, name='Xception')\n    return model\n\nclass LearningRateSchedule(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch+1)%2 == 0:\n            lr = K.get_value(self.model.optimizer.lr)\n            K.set_value(self.model.optimizer.lr, lr*0.94)\n\ninput_shape = (160, 160, 3)\n\nX_train = X_train.astype('float32')/255.\nX_test = X_test.astype('float32')/255.\n\ny_train = to_categorical(y_train, num_classes=2)\ny_test = to_categorical(y_test, num_classes=2)\n\nmodel_input = Input(shape=input_shape)\n\nmodel = Xception(model_input,2)\n\n# optimizer = SGD(lr=0.0009, momentum=0.9)\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-8, decay=1e-5, amsgrad=False)\n\ncallbacks_list = [LearningRateSchedule()]\n\nmodel.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n\nmodel.fit(X_train, y_train, batch_size=64, epochs=40, validation_split=0.25, callbacks=callbacks_list)\n\ny_pred = model.predict(X_test)\n\na = log_loss(y_test,y_pred)\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('XceptionDense.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test[10:20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred[10:20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(X_train)):\n    a = model.predict(X_train[i].reshape(1,160,160,3))\n    print(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def divide(x, y, train_prop):\n    random.seed(1234)\n    tmp = np.random.permutation(np.arange(len(x)))\n    X_train = x[tmp][:-(len(x)-round(train_prop * len(x)))]\n    y_train = y[tmp][:-(len(x)-round(train_prop * len(x)))]\n    X_test = x[tmp][-(len(x)-round(train_prop * len(x))):]\n    y_test = y[tmp][-(len(x)-round(train_prop * len(x))):]\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = divide(A,B,0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('image_model_test1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\ny = []\n\nfor i in range(11,20):\n    path = all_train_dirs[i]\n    file_list = os.listdir(path)\n    label = pd.read_csv(all_train_dirs[i] + '/metadata.csv',delimiter=',')\n    img,label = read_image(path,file_list,label)\n    X += img\n    y += label\n\nX = np.array(X)\ny = np.array(y).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.astype('float32')/255.\nX_test = X_test.astype('float32')/255.\n\ny_pred = model.predict(X_test)\na = log_loss(y_test,y_pred)\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.load_model('/kaggle/input/imagemodel/image_model_0.3030.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('image_test.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom PIL import Image\nimport cv2, sys, re\nimport pandas as pd\nimport numpy as np\nimport random\nfrom keras import models,Sequential,layers\nfrom keras.models import Model, Input\nfrom keras.layers import Conv2D, SeparableConv2D, Dense, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, BatchNormalization, Dropout,Flatten,Reshape\nfrom keras.layers import Add\nfrom keras.utils import to_categorical\nfrom keras.callbacks import Callback\nfrom keras.optimizers import SGD,Adam\nfrom keras.regularizers import l2\nfrom keras.datasets import cifar10\nimport numpy as np\nimport keras.backend as K\nfrom sklearn.metrics import log_loss\nimport glob\nfrom keras.models import load_model\nimport tensorflow as tf\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_train_dirs = glob.glob('/kaggle/input/' + 'deepfake-detection-faces-*')\n\nmodel = tf.keras.models.load_model('/kaggle/input/imagemodel/image_model_0.3030.h5')\n# model = tf.keras.models.load_model('/kaggle/input/image-test1/image_test.h5')\n\n\ndef read_image(path,file_list,label_img):\n    a = [1]\n    im = []\n    label = []\n    for i in file_list:\n        path_dir = path +'/' + i\n        for j in a:\n            try:\n                img = Image.open(path_dir + '/' + str(j) +'.png')\n#                 img = img[0,:,:,0].reshape(160,160,1)\n#                 arr_img = list(np.array(img)[:,:,0].reshape(160,160,1))\n                arr_img = list(np.array(img))\n\n                im.append(arr_img)\n\n                label_list = np.array(label_img.iloc[:, [2]])\n\n                if i + '.mp4' in label_list:\n                    label.append(1)  # Deepfake\n                else:\n                    label.append(0)\n            except:\n                pass\n    return im, label\n\n\nX = []\ny = []\n# all_train_dirs\nfor i in range(1):\n    path = all_train_dirs[i]\n    file_list = os.listdir(path)\n    label = pd.read_csv(all_train_dirs[i] + '/metadata.csv',delimiter=',')\n    img,label = read_image(path,file_list,label)\n    X += img\n    y += label\n\nX = np.array(X)\ny = np.array(y).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def reduce_mem_usage(df):\n#     \"\"\" iterate through all the columns of a dataframe and modify the data type\n#         to reduce memory usage.        \n#     \"\"\"\n#     start_mem = df.memory_usage().sum() / 1024**2\n#     print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n#     for col in df.columns:\n#         col_type = df[col].dtype\n        \n#         if col_type != object:\n#             c_min = df[col].min()\n#             c_max = df[col].max()\n#             if str(col_type)[:3] == 'int':\n#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n#                     df[col] = df[col].astype(np.int8)\n#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n#                     df[col] = df[col].astype(np.int16)\n#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n#                     df[col] = df[col].astype(np.int32)\n#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n#                     df[col] = df[col].astype(np.int64)  \n#             else:\n#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n#                     df[col] = df[col].astype(np.float16)\n#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n#                     df[col] = df[col].astype(np.float32)\n#                 else:\n#                     df[col] = df[col].astype(np.float64)\n#         else:\n#             df[col] = df[col].astype('category')\n\n#     end_mem = df.memory_usage().sum() / 1024**2\n#     print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n#     print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n#     return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터셋 0,1로 분류해서 인덱싱 하기 위함\nc = []\nd = []\ne = []\nf = []\n\n\nfor i in range(len(y)):\n    if y[i] == 0:\n        c.append(y[i])\n        d.append(X[i])\n\nfor i in range(len(y)):\n    if y[i] == 1:\n        e.append(y[i])\n        f.append(X[i])\n\nX = np.array(f+d)\ny = np.array(e+c).reshape(-1,1)\n\na=0\nfor i in range(len(y)):\n    if y[i] == 1:\n        a += 1\nprint(a)\n\nprint(len(X))\nprint(len(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del a\ndel c\ndel d\ndel e\ndel f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"A = X[:88]\nB = y[:88]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X\ndel y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_output = model.layers[-3].output\nmodel = tf.keras.models.Model(inputs=model.input, outputs=first_output)\na = model.predict(A)\nprint(a.shape)\n\nb = []\nfor i in range(len(a)):\n    b.append(a[i].flatten())\nb = np.array(b)\nprint(b.shape)\n\nc = B.reshape(-1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def divide(x, y, train_prop):\n    random.seed(1234)\n    tmp = np.random.permutation(np.arange(len(x)))\n    X_train = x[tmp][:-(len(x)-round(train_prop * len(x)))]\n    y_train = y[tmp][:-(len(x)-round(train_prop * len(x)))]\n    X_test = x[tmp][-(len(x)-round(train_prop * len(x))):]\n    y_test = y[tmp][-(len(x)-round(train_prop * len(x))):]\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = divide(X,y,0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lightgbm 사용 시\n\ndef divide(x, y, train_prop):\n    random.seed(1234)\n    tmp = np.random.permutation(np.arange(len(x)))\n    X_train = x[tmp][:-(len(x)-round(train_prop * len(x)))]\n    y_train = y[tmp][:-(len(x)-round(train_prop * len(x)))]\n    X_test = x[tmp][-(len(x)-round(train_prop * len(x))):]\n    y_test = y[tmp][-(len(x)-round(train_prop * len(x))):]\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_val, y_val = divide(b,c,0.8)\n\ndef divide(x, y, train_prop):\n    random.seed(1234)\n    tmp = np.random.permutation(np.arange(len(x)))\n    X_train = x[tmp][:-(len(x)-round(train_prop * len(x)))]\n    y_train = y[tmp][:-(len(x)-round(train_prop * len(x)))]\n    X_test = x[tmp][-(len(x)-round(train_prop * len(x))):]\n    y_test = y[tmp][-(len(x)-round(train_prop * len(x))):]\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = divide(X_train,y_train,0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_feature(data_set, feature_num):\n    feature_size = a.shape[1]*a.shape[2]\n    data_set = data_set[:,:feature_size*feature_num]\n    data_set = data_set.flatten()\n    data_set = data_set.reshape(-1,400)\n    return data_set\nX_train = make_feature(X_train,20)\nprint(X_train.shape)\nX_val = make_feature(X_val,20)\nprint(X_val.shape)\nX_test = make_feature(X_test,20)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = list(y_train)\ny_test = list(y_test)\n\ndef make_label(data_label,feature_num):\n    d = []\n    for i in range(len(data_label)):\n        d.append(data_label[i]+[0]*feature_num)\n    d = np.array(d)\n    d = d.flatten()\n    return d\ny_train = make_label(y_train,20)\nprint(y_train.shape)\ny_val = make_label(y_val,20)\nprint(y_val.shape)\ny_test = make_label(y_test,20)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del b\ndel c\ndel A\ndel B","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def divide(x, y, train_prop):\n#     random.seed(1234)\n#     tmp = np.random.permutation(np.arange(len(x)))\n#     X_train = x[tmp][:-(len(x)-round(train_prop * len(x)))]\n#     y_train = y[tmp][:-(len(x)-round(train_prop * len(x)))]\n#     X_test = x[tmp][-(len(x)-round(train_prop * len(x))):]\n#     y_test = y[tmp][-(len(x)-round(train_prop * len(x))):]\n#     return X_train, y_train, X_test, y_test\n\n# X_train, y_train, X_test, y_test = divide(A,B,0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def divide(x, y, train_prop):\n    random.seed(1234)\n    X_train = x[:-(len(x)-round(train_prop * len(x)))]\n    y_train = y[:-(len(x)-round(train_prop * len(x)))]\n    X_test = x[-(len(x)-round(train_prop * len(x))):]\n    y_test = y[-(len(x)-round(train_prop * len(x))):]\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = divide(k,d,0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 50, random_state = 0)\n# max_features=1,, bootstrap=False\n\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf.predict_proba(X_test)\n\ndef assemble(test,feature_num):\n    pred_test = []\n    assemble_num = int(len(test)/feature_num)\n    for i in range(assemble_num):\n        pred_test.append(np.mean(test[feature_num*i:feature_num*(i+1),0]))\n    pred_test = np.array(pred_test)\n    return pred_test\n\ny_pred_sum = assemble(y_pred,20)\n\ndef assemble_label(test,feature_num):\n    pred_test = []\n    assemble_num = int(len(test)/feature_num)\n    for i in range(assemble_num):\n        pred_test.append(np.mean(test[feature_num*i:feature_num*(i+1)]))\n    pred_test = np.array(pred_test)\n    return pred_test\n\ny_test_sum = assemble_label(y_test,20)\ny_test_sum = y_test_sum.astype('int64')\n\nscore = log_loss(y_test,y_pred)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\ntrain_ds = lgb.Dataset(X_train, label = y_train) \nval_ds = lgb.Dataset(X_val, label = y_val) \n\nparams = {'learning_rate': 0.01,\n          'max_depth': -1,\n          'boosting': 'gbdt',\n          'objective': 'binary',\n          'metric': 'binary',\n          'is_training_metric': True,\n#           'feature_fraction': 1,\n          'bagging_fraction': 0.7,\n          'save_binary':True,\n          'scale_pos_weight':1.2,\n          'seed':2020}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(params, train_ds, 3000, val_ds, verbose_eval=100)\n# , early_stopping_rounds=100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\nscore = log_loss(y_test,y_pred)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def assemble(test,feature_num):\n    pred_test = []\n    assemble_num = int(len(test)/feature_num)\n    for i in range(assemble_num):\n        pred_test.append(np.mean(test[feature_num*i:feature_num*(i+1)]))\n    pred_test = np.array(pred_test)\n    return pred_test\n\ny_pred_sum = assemble(y_pred,20)\n\ny_test_sum = assemble(y_test,20)\ny_test_sum = y_test_sum.astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test_sum[:30])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred[:30])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.externals import joblib\nfrom lightgbm import LGBMClassifier\n\n# save model\njoblib.dump(model, 'light_binary.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load model\nmodel = joblib.load('/kaggle/input/light1/light1.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[1] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_probs = model.predict(X_train)\nscore = log_loss(y_train,rf_probs)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rf_probs[:500])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}