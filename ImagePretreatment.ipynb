{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2, sys, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from keras import models,Sequential,layers\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Conv2D, SeparableConv2D, Dense, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers import Activation, BatchNormalization, Dropout, Flatten, Reshape\n",
    "from keras.layers import Add\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import log_loss\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Conv2D, BatchNormalization, ReLU, DepthwiseConv2D, Activation, Input, Add\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Softmax, Flatten\n",
    "\n",
    "# ** to update custom Activate functions\n",
    "from keras.utils.generic_utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 데이터를 불러오기 위한 Directory 지정\n",
    "all_train_dirs = glob.glob('/kaggle/input/all-data/dfdc_train_part/' + 'dfdc_train_part_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 CascadeClassifier 함수 활용하여 눈으로 인식하는 갯수를 이용하여\n",
    "# 1개일 시 옆모습, 1개 이외일 시 정면으로 지정하여 데이터셋을 나눔\n",
    "eye_cascade = cv2.CascadeClassifier('/kaggle/input/haar-cascades-for-face-detection/haarcascade_eye.xml')\n",
    "\n",
    "def detection_eyes(a):\n",
    "    roi_gray = a[0:160,0:160]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    cnt_eyes = 0\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cnt_eyes += 1\n",
    "    return cnt_eyes\n",
    "\n",
    "\n",
    "# 위의 함수를 이용하여 이미지를 불러와 Numpy 형식으로 변환 (옆,앞모습 데이터셋도 나눔)\n",
    "def read_image(path,file_list,label_img):\n",
    "    # a는 한 동영상에서 생성된 이미지의 번호를 입력한다. (원하는 이미지를 저장하게 됨)\n",
    "    a = [150,250]\n",
    "    im = []\n",
    "    label = []\n",
    "    for i in file_list:\n",
    "        path_dir = path +'/' + i\n",
    "        for j in a:\n",
    "            try:\n",
    "                # 이미지를 Numpy 형식으로 변환\n",
    "                img = Image.open(path_dir + '/' + str(j) +'.png')\n",
    "                arr_img = np.array(img)\n",
    "                # 눈의 갯수로 옆, 앞모습을 나눔\n",
    "                if detection_eyes(arr_img) == 1:\n",
    "#                 if detection_eyes(arr_img) != 1:\n",
    "                    im.append(list(arr_img))\n",
    "                    label_list = np.array(label_img.iloc[:, [2]])\n",
    "                # Labeling 작업\n",
    "                    if i + '.mp4' in label_list:\n",
    "                        label.append(1)  # Deepfake\n",
    "                    else:\n",
    "                        label.append(0)\n",
    "            except:\n",
    "                pass\n",
    "    return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_image 함수를 이용하여 지정한 이미지를 저장하는 작업\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(all_train_dirs)):\n",
    "    path = all_train_dirs[i]\n",
    "    file_list = os.listdir(path)\n",
    "    label = pd.read_csv(all_train_dirs[i] + '/metadata.csv',delimiter=',')\n",
    "    img,label = read_image(path,file_list,label)\n",
    "    X += img\n",
    "    y += label\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savez를 이용하여 이미지와 라벨을 한번에 저장\n",
    "# (데이터를 npz형태로 저장하여 사용함으로써, 데이터 불러오는 시간을 줄임)\n",
    "np.savez('Facial.npz',X,y)\n",
    "# np.savez('Side.npz',X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Version\n",
    "\n",
    "# Numpy 데이터 불러오기 (이미지, 라벨이 묶여서 저장되어 있음)\n",
    "# arr_0은 이미지, arr_1은 label\n",
    "# 1만개의 Deepfake, 5만개의 Real 이미지가 순서대로 있음\n",
    "# np.r_을 사용하여 Numpy로 불러온 이미지를 필요한 만큼 쓰기 위해 사용\n",
    "# (224,224,3) Shape을 (-1,224,224,3) Shape으로 붙임\n",
    "\n",
    "arr = np.load('/kaggle/input/newdata/new_data_side.npz','r')\n",
    "\n",
    "X = arr['arr_0']\n",
    "y = arr['arr_1']\n",
    "\n",
    "\n",
    "# 데이터 Shuffle\n",
    "\n",
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "\n",
    "X = X[s]\n",
    "y = y[s]\n",
    "\n",
    "\n",
    "# 데이터 Augumentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# flow_from_directory는 폴더를 지정해주지만, flow는 데이터를 직접 입력시킨다\n",
    "# flow에 데이터를 입력할 때, (이미지, 라벨) 형식으로 사용\n",
    "train_generator = train_datagen.flow(\n",
    "    # This is the target directory\n",
    "    (X_train,y_train),\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    (X_val,y_val),\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Version\n",
    "\n",
    "arr = np.load('/kaggle/input/newdata/new_data_side.npz','r')\n",
    "\n",
    "X = arr['arr_0']\n",
    "y = arr['arr_1']\n",
    "\n",
    "# 데이터 Augumentation을 위해 Validation Set의 비율을 크게 함\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.35, random_state=1)\n",
    "del X\n",
    "del y\n",
    "\n",
    "# img_size는 EfficientNet을 사용하기 때문에, 이미지를 많이 사용할 수 있도록\n",
    "# 120X120의 형태로 진행. (160, 224 크기로 확인하였으나, 120 사이즈의 결과가 좋았음)\n",
    "# mean, std는 이미지 RGB 각각을 따로 지정하여 정규화\n",
    "img_size = 120\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "# 데이터 Augumentation\n",
    "class ImageTransform_train:\n",
    "    def __init__(self, size, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "                transforms.Resize((size, size), interpolation=Image.BILINEAR),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n",
    "    \n",
    "class ImageTransform_val:\n",
    "    def __init__(self, size, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "                transforms.Resize((size, size), interpolation=Image.BILINEAR),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n",
    "    \n",
    "transform_train = ImageTransform_train(img_size, mean, std)\n",
    "transform_val = ImageTransform_val(img_size, mean, std)\n",
    "\n",
    "\n",
    "# 위의 함수를 이용하여 Numpy형식을 Tensor로 변환 및 Augumentation\n",
    "# 메모리 활용을 위해 필요없는 데이터는 즉시 삭제\n",
    "img_list = []\n",
    "\n",
    "for image in X_train:     \n",
    "    try:\n",
    "        image = Image.fromarray(image)\n",
    "        image = transform_train(image)\n",
    "        img_list.append(image)\n",
    "    except:\n",
    "        img_list.append(None)\n",
    "\n",
    "del X_train\n",
    "\n",
    "img_list_val = []\n",
    "\n",
    "for image in X_val:          \n",
    "    try:\n",
    "        image = Image.fromarray(image)\n",
    "        image = transform_val(image)\n",
    "        img_list_val.append(image)\n",
    "    except:\n",
    "        img_list_val.append(None)\n",
    "    \n",
    "del X_val\n",
    "\n",
    "# Label Numpy형식 데이터를 Tensor로 변환\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "\n",
    "# 훈련 시 Loss 값을 시각화 하기 위해 사용\n",
    "train_len = len(X_train)\n",
    "val_len = len(X_val)\n",
    "dataset_sizes = {'train':train_len,'val':val_len}\n",
    "\n",
    "\n",
    "# 데이터 Loader\n",
    "# Train Set과 Validation Set을 나눠서 진행\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class JoinDataset_train(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = y_train.shape[0]\n",
    "        self.x_data = img_list\n",
    "        self.y_data = y_train\n",
    "\n",
    "    \"\"\" Diabetes dataset.\"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "trainset = JoinDataset_train()\n",
    "train_loader = DataLoader(dataset=trainset,batch_size=64,shuffle=True)\n",
    "\n",
    "\n",
    "class JoinDataset_val(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = y_val.shape[0]\n",
    "        self.x_data = img_list_val\n",
    "        self.y_data = y_val\n",
    "\n",
    "    \"\"\" Diabetes dataset.\"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "valset = JoinDataset_val()\n",
    "val_loader = DataLoader(dataset=valset,batch_size=64,shuffle=True)\n",
    "\n",
    "dataloders = {'train':train_loader,'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "위는 데이터 정제\n",
    "-----------------------------------------절취선\n",
    "아래는 Features 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature map 시각화 (원하는 Layer를 지정하여 Features를 확인할 수 있다)\n",
    "# PPT 이미지에 포함시킴\n",
    "\n",
    "# 이미지 불러오기\n",
    "def load_image(img_path, target_size):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
    "    img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # 배치 사이즈 추가 + 스케일링 결과 반환\n",
    "    return img_tensor[np.newaxis] / 255     # (1, 150, 150, 3)\n",
    "\n",
    "\n",
    "# 첫 번째 등장하는 컨볼루션 레이어의 모든 피처맵(32개) 출력\n",
    "def show_first_feature_map(loaded_model, img_path):\n",
    "    # layers[?] : Layer 번호를 지정하여 특정 Layer에서 생성되는 Feature를 확인할 수 있다\n",
    "    first_output = loaded_model.layers[2].output\n",
    "    print(first_output.shape, first_output.dtype)\n",
    "\n",
    "    # 1개의 출력을 갖는 새로운 모델 생성\n",
    "    model = tf.keras.models.Model(inputs=loaded_model.input, outputs=first_output)\n",
    "\n",
    "    # 입력으로부터 높이와 너비를 사용해서 target_size에 해당하는 튜플 생성\n",
    "    target_size = (loaded_model.input.shape[2], loaded_model.input.shape[2])\n",
    "    img_tensor = load_image(img_path, target_size)\n",
    "\n",
    "    print(loaded_model.input.shape)     \n",
    "    print(img_tensor.shape)          \n",
    "\n",
    "    first_activation = model.predict(img_tensor)\n",
    "\n",
    "    print(first_activation.shape)       \n",
    "    print(first_activation[0, 0, 0]) \n",
    "\n",
    "    # first_activation 콜론(:)은 높이와 너비를 가리키는 차원의 모든 데이터\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i in range(first_activation.shape[-1]):\n",
    "        plt.subplot(4, 8, i + 1)\n",
    "\n",
    "        # 눈금 제거. fignum은 같은 피켜에 연속 출력\n",
    "        plt.axis('off')\n",
    "        plt.matshow(first_activation[0, :, :, i], cmap='gray', fignum=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 위의 함수를 이용하여, 지정 이미지에서 생성되는 Feature를 출력\n",
    "show_first_feature_map(model,'/kaggle/input/deepfake-detection-faces-part-3-0/vezsoxophr/150.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
